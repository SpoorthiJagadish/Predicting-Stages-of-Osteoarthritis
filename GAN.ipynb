{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Define the generator model\n",
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7 * 7 * 256, input_dim=100))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "    model.add(Conv2DTranspose(128, kernel_size=5, strides=1, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=5, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(1, kernel_size=5, strides=2, padding='same', activation='tanh'))\n",
    "    return model\n",
    "\n",
    "# Define the discriminator model\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=5, strides=2, padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128, kernel_size=5, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "# Define the WGAN model\n",
    "def build_wgan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "# Define the Wasserstein loss function\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return -K.mean(y_true * y_pred)\n",
    "\n",
    "# Build the generator and discriminator models\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# Build the WGAN model\n",
    "wgan = build_wgan(generator, discriminator)\n",
    "\n",
    "# Compile the WGAN model\n",
    "wgan.compile(optimizer=RMSprop(lr=0.00005), loss=wasserstein_loss)\n",
    "\n",
    "# Train the WGAN model\n",
    "def train_wgan(x_train, epochs, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(x_train.shape[0] // batch_size):\n",
    "            # Train the discriminator\n",
    "            for _ in range(5):\n",
    "                noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "                fake_images = generator.predict(noise)\n",
    "                real_images = x_train[np.random.randint(0, x_train.shape[0], batch_size)]\n",
    "                discriminator_loss_real = discriminator.train_on_batch(real_images, -np.ones(batch_size))\n",
    "                discriminator_loss_fake = discriminator.train_on_batch(fake_images, np.ones(batch_size))\n",
    "                discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
    "                for layer in discriminator.layers:\n",
    "                    weights = layer.get_weights()\n",
    "                    weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "                    layer.set_weights(weights)\n",
    "            \n",
    "            # Train the generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "            generator_loss = wgan.train_on_batch(noise, -np.ones(batch_size))\n",
    "        \n",
    "        # Print the losses\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Discriminator Loss: {discriminator_loss} - Generator Loss: {generator_loss}\")\n",
    "\n",
    "# Train the WGAN model\n",
    "train_wgan(x_train, epochs=100, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
