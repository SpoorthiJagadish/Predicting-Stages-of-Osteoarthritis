{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 12:24:40.664713: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-25 12:24:40.841455: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-25 12:24:41.622738: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/student/anaconda3/envs/tensorflow/lib/python3.10/site-packages/cv2/../../lib64:/home/student/anaconda3/envs/tensorflow/lib\n",
      "2024-04-25 12:24:41.622852: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/student/anaconda3/envs/tensorflow/lib/python3.10/site-packages/cv2/../../lib64:/home/student/anaconda3/envs/tensorflow/lib\n",
      "2024-04-25 12:24:41.622862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import cv2 as cv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Dense, BatchNormalization, Conv2D, Conv2DTranspose, ReLU, LeakyReLU, Flatten, MaxPooling2D, Dropout, Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 536\n"
     ]
    }
   ],
   "source": [
    "knee_images = len(os.listdir(os.path.join(dataset_path, '4')))\n",
    "print(\"Number of images:\", knee_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['4']\n",
    "count = [knee_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(dataset_path, \"4\")\n",
    "\n",
    "image_files = os.listdir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "# fig.suptitle('Normal Images', fontsize=16)\n",
    "# axes = axes.ravel()\n",
    "\n",
    "# for i, img_file in enumerate(image_files[:9]):\n",
    "#     image_path = os.path.join(image_path, img_file)\n",
    "#     image = cv2.imread(image_path)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     axes[i].imshow(image)\n",
    "#     axes[i].axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 64000\n",
    "BATCH_SIZE = 32\n",
    "batch_size = BATCH_SIZE\n",
    "EPOCHS = 2500\n",
    "latent_dim = 128\n",
    "input_size = [256*2, 256*2, 3]\n",
    "image_size = (256*2, 256*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 536 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255   \n",
    ")\n",
    "\n",
    "dataset_normal= datagen.flow_from_directory(\n",
    "    os.path.join(dataset_path),  \n",
    "    classes=['4'],\n",
    "    target_size=image_size,        \n",
    "    batch_size=BATCH_SIZE,      \n",
    "    class_mode='binary',        \n",
    "    shuffle=True                 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 12:24:43.145535: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-25 12:24:43.152664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-25 12:24:43.152788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-25 12:24:43.153479: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-25 12:24:43.155220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-25 12:24:43.155333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-25 12:24:43.155379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-25 12:24:44.043124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-25 12:24:44.043250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-25 12:24:44.043261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-25 12:24:44.043312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-25 12:24:44.043351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13541 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16384)             2113536   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 28)       114716    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16, 16, 28)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 28)       12572     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 28)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 28)       12572     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 64, 64, 28)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 128, 128, 28)     12572     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128, 128, 28)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 256, 256, 28)     12572     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 256, 256, 28)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 512, 512, 28)     12572     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 512, 512, 28)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 512, 512, 3)       1347      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,292,459\n",
      "Trainable params: 2,292,459\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 256, 256, 28)      1372      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256, 256, 28)     112       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 256, 256, 28)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 28)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 28)        12572     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64, 64, 28)       112       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 64, 64, 28)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 28)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 28)        12572     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 28)       112       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 16, 16, 28)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 28)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 4, 4, 28)          12572     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 28)         112       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 4, 4, 28)          0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 28)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 112)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 28)                3164      \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 28)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 28)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 29        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,729\n",
      "Trainable params: 42,505\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def gen_model():\n",
    "    model = Sequential([\n",
    "        Input(shape=(latent_dim,)),\n",
    "        Dense(8 * 8 * 256),\n",
    "        Reshape((8, 8, 256)),\n",
    "        Conv2DTranspose(28, kernel_size=4, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Conv2DTranspose(28, kernel_size=4, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Conv2DTranspose(28, kernel_size=4, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Conv2DTranspose(28, kernel_size=4, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Conv2DTranspose(28, kernel_size=4, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Conv2DTranspose(28, kernel_size=4, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Conv2D(3, kernel_size=4, padding='same', activation='sigmoid')\n",
    "    ],\n",
    "        name=\"generator\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def disc_model():\n",
    "    model = Sequential([\n",
    "        Input(shape=input_size),\n",
    "        Conv2D(28, kernel_size=4, strides=2, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        MaxPooling2D(strides=2),\n",
    "        Conv2D(28, kernel_size=4, strides=2, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        MaxPooling2D(strides=2),\n",
    "        Conv2D(28, kernel_size=4, strides=2, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        MaxPooling2D(strides=2),\n",
    "        Conv2D(28, kernel_size=4, strides=2, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        MaxPooling2D(strides=2),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(28),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ],\n",
    "        name=\"discriminator\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "generator = gen_model()\n",
    "generator.summary()\n",
    "\n",
    "discriminator = disc_model()\n",
    "discriminator.summary()\n",
    "\n",
    "class Gan(Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def compile(self, disc_opt, gen_opt, loss_function):\n",
    "        super().compile()\n",
    "        self.disc_opt = disc_opt\n",
    "        self.gen_opt = gen_opt\n",
    "        self.loss_function = loss_function\n",
    "        self.disc_loss_metric = tf.keras.metrics.Mean(name=\"disc_loss\")\n",
    "        self.gen_loss_metric = tf.keras.metrics.Mean(name=\"gen_loss\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.disc_loss_metric, self.gen_loss_metric]\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        real_images, real_labels = data  # Accept labels separately\n",
    "\n",
    "        # Generate random latent vectors\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Generate fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine real and fake images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Concatenate the real and fake labels\n",
    "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Discriminator training\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            disc_loss = self.loss_function(labels, predictions)\n",
    "\n",
    "        grads = tape.gradient(disc_loss, self.discriminator.trainable_weights)\n",
    "        self.disc_opt.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        # Generator training\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            gen_loss = self.loss_function(misleading_labels, predictions)\n",
    "\n",
    "        grads = tape.gradient(gen_loss, self.generator.trainable_weights)\n",
    "        self.gen_opt.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update loss metrics\n",
    "        self.disc_loss_metric.update_state(disc_loss)\n",
    "        self.gen_loss_metric.update_state(gen_loss)\n",
    "\n",
    "        return {\n",
    "            \"disc_loss\": self.disc_loss_metric.result(),\n",
    "            \"gen_loss\": self.gen_loss_metric.result()\n",
    "        }\n",
    "    \n",
    "def gen_images(generator, current_epoch, num_of_samples=2):\n",
    "    noise = tf.random.normal([num_of_samples, latent_dim], dtype=tf.float32)\n",
    "    generated_images = generator(noise, training=False)\n",
    "    \n",
    "    figure = plt.figure(figsize=(20, 20))\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "        plt.title(f\"After epoch {current_epoch}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig(f'After_epochs_{current_epoch:04d}.png')\n",
    "    plt.show()\n",
    "\n",
    "class Gan_Callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, num_images=2, latent_dim=128):\n",
    "        self.num_images = num_images\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        latent_vectors = tf.random.normal(shape=(self.num_images, self.latent_dim))\n",
    "        generated_images = self.model.generator(latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images = generated_images.numpy()  # Removed redundant line\n",
    "\n",
    "        figure = plt.figure(figsize=(10, 10))\n",
    "        for i in range(generated_images.shape[0]):\n",
    "            plt.subplot(2, 2, i + 1)\n",
    "            plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "            plt.title(f\"After epoch {epoch + 1}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.savefig('After_epochs_{:04d}.png'.format(epoch + 1))\n",
    "        plt.show()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            self.model.generator.save('Saved_Models/gen.h5')\n",
    "            self.model.discriminator.save('Saved_Models/disc.h5')\n",
    "\n",
    "gan = Gan(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "disc_opt=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), \n",
    "gen_opt=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "# Parallel gpu computing won't work unless  we pass reduction=tf.keras.losses.Reduction.NONE as a parameter too.\n",
    "loss_function=tf.keras.losses.BinaryCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper funtion to help us with loadidng images in batches\n",
    "def image_loader(generator):\n",
    "    for images, labels in generator:\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual traing begins here\n",
    "history = gan.fit(\n",
    "    image_loader(dataset_normal), \n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=len(dataset_normal),  \n",
    "    callbacks=[Gan_Callback(num_images=4, latent_dim=latent_dim)]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
